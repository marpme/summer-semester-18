{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbor (kNN)\n",
    "\n",
    "Implementierten Sie den kNN-Klassifikator basierend auf folgenden Arbeitsschritten: \n",
    "\n",
    "- Laden des Datensatzes und aufteilen in Trainings- und Testdaten.\n",
    "- Erinnern der Daten in der Trainingsphase \n",
    "- Vergleichen jedes Testbilds mit allen erinnerten Trainingsbildern in der Vorhersage-Phase und übernehmen des Klassennamens, der `k` ähnlichsten Trainingsbeispiele\n",
    "- Ermitteln des besten `k` durch Kreuzvalidierung\n",
    "- Darstellen der nächsten `k` Trainingsbilder zu je einem Testbild aus jeder Klasse\n",
    "\n",
    "Einige Aufgaben sind nicht notwendig, sodass Sie ein insgesamt läuffahiges Notebook erhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization of some basic modules and global parameters\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot figures inline and set some global parameters for plotting\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatzinitialisierung und -aufbereitung\n",
    "\n",
    "Bei dem Datensatz, den Sie klassifizieren sollen, handelt es sich um den [Cifar10-Datensatz](https://www.cs.toronto.edu/~kriz/cifar.html). Grundsätzlich handelt es sich dabei um kleine Bilder, die in zehn Klassen unteteilt sind. Machen Sie sich mit dem Aufbau vertraut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\"\n",
    "    Opens and decodes a single batch of the cifar10 dataset.\n",
    "\n",
    "    Input: \n",
    "    - A string containing the absolute path to a batch file ('rb' stands for read binary)\n",
    "    \n",
    "    Output:\n",
    "    - An array containing the data\n",
    "    - An array containing the labels \n",
    "    \"\"\"  \n",
    "    with open(filename, 'rb') as f:      \n",
    "        #####################################################################\n",
    "        # TODO (0):                                                         #\n",
    "        # Use pickle.load() to read the cifar10 data into a dictonary.      #\n",
    "        # Create a parameter X for the image data and a parameter Y for the #\n",
    "        # labels.                                                           #\n",
    "        #####################################################################\n",
    "        datadict = pickle.load(f, encoding='bytes')\n",
    "        X = datadict[b'data']\n",
    "        Y = datadict[b'labels']\n",
    "        #####################################################################\n",
    "        #                       END OF YOUR CODE                            #\n",
    "        #####################################################################        \n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float64\")\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load_CIFAR10(root_folder):\n",
    "    \"\"\"\n",
    "    Load training and test data of the cifar10 dataset into arrays.\n",
    "\n",
    "    Input: \n",
    "    - A string containing the absolute path to the cifar 10 dataset folder\n",
    "    \n",
    "    Output:\n",
    "    - Array containing the image data for the trainings set\n",
    "    - Array containing the image labels for the trainings set\n",
    "    - Array containing the image data for the test set\n",
    "    - Array containing the image labels for the test set\n",
    "    \"\"\" \n",
    "    xs = []\n",
    "    ys = []\n",
    "    # Load and decode each batch of the trainings set\n",
    "    for batch in range(1,6):\n",
    "        f = os.path.join(root_folder, 'data_batch_%d' % (batch, ))\n",
    "        print(f)\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    # Create one ndarray from the single batches for data and labels\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    # Load and decode test data and labels  \n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(root_folder, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "#####################################################################\n",
    "# TODO (0):                                                         #\n",
    "# Download the Cifar10 (run script get_datasets.sh) Python version  #\n",
    "# into your directroy, unzip and point to it.                       #                                                             \n",
    "#####################################################################\n",
    "cifar10_dir = 'cifar-10-batches-py'  # default dir\n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Kontrolle, ob die Daten korrekt geladen wurden und zur Veranschaulichung, implementieren Sie eine Visualisierung von `x` **zufälligen** Beispielbilder für jede Klasse des Cifar10-Datensatzes aus der Trainingsmenge mit dem Label als Spaltenüberschrift ohne sichtbare Achsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot k random examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "#####################################################################\n",
    "# TODO (0):                                                         #\n",
    "# Plot a figure where the colums are equal to the number of classes #\n",
    "# and rows are defined by the number of samples per class. Each     #\n",
    "# sample should be a random image from training data. Add class     #\n",
    "# labels as title and remove axis from the figure.                  #\n",
    "#                                                                   #\n",
    "# Hint: Keep an eye on the cifar10 data encoding.                   # \n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Kalkulation des Klassifikators zu reduzieren, verwenden Sie für die Berechnung nur eine Teilmenge der Traings- bzw. Testdaten. Ferner müssen die Bilddaten für die weitere Verarbeitung so umgeformt werden, dass aus der drei dimensionalen Bilddarstellung einen ein dimensionale wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Subsample trainings data \n",
    "num_training = 5000\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# Subsample test data \n",
    "num_test = 500\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Reshape each image data into a 1-dim array\n",
    "print (X_train.shape, X_test.shape) # Should be: (5000, 32, 32, 3) (500, 32, 32, 3)\n",
    "\n",
    "#####################################################################\n",
    "# TODO (0):                                                         #\n",
    "# Reshape the image data to one dimension.                          #\n",
    "#                                                                   #\n",
    "# Hint: Look at the numpy reshape function and have a look at -1    # \n",
    "#       option                                                      #\n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################\n",
    "\n",
    "print (X_train.shape, X_test.shape) # Should be: (5000, 3072) (500, 3072)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Klassifikation mit kNN\n",
    "\n",
    "Der `kNN`-Klassifikator ist in einem eignen Skript untergebracht, sodass der Klassifikator in dem Workflow austauschbar ist. Zunächst muss dieser also initialisiert werden. Das Training eines kNN ist - verglichen mit neurolanen Netzwerken - trivial. Der Klassifikator speichert die Daten für sich ab und macht in der Trainingsphase nichts weiteres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from k_nearest_neighbor_total import KNearestNeighbor\n",
    "\n",
    "# Create a kNN classifier instance. \n",
    "# Remember that training a kNN classifier is a noop: \n",
    "# the Classifier simply remembers the data and does no further processing \n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der entscheidene Schritt beim `kNN`-Klassifikator passiert während der Klassifikation selbst. Wie oben kurz erwähnt, wird ein Testbild gegen die Trainingsbilder vergleichen und dies in Abhängigkeit von einer Variablen `k`. Der folgende Prozess lässt sich in zwei Kernschritte zerlegen:\n",
    "\n",
    "- Berechnung der Distanzen von jedem Testbild zu allen Trainingsbildern.\n",
    "- Finden der `k` geringsten Distanzen zu dem jeweiligen Testbild und vergeben der resultierenden Klasse.\n",
    "\n",
    "Um den Trainingsprozess umzusetzten, öffnen Sie das Skript `k_nearest_neighbor.py` im Ordner `/ak1163051/classifiers` und Implementieren Sie die Funktion `compute_distances_with_loops`. Hier soll eine Matrix mit dem [Euklidischer Abstand](https://en.wikipedia.org/wiki/Euclidean_distance) (L2) zwischen allen Trainingsdaten und Testdaten erzeugt werden. Die Umsetzung erfolgt durche eine doppelte Schleife, die über alle Elemente iteriert und den jeweiligen Abstand berechnet. Diese Variante ist offensichtlich nicht sehr effizient und kann bei großen Datensätzen zu Problemen führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this cell: open `ak1163051/k_nearest_neighbor.py` and 'implement compute_distances_with_loops`\n",
    "\n",
    "# Compute the distance between the test data and trainings data\n",
    "dists = classifier.compute_distances_with_loops(X_test)\n",
    "print(dists.shape) # Should be: (500, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein eleganterer und effizienterer Weg die Distanzberechnung zu implementieren wird durch die Vektordarstellung der Daten ermöglicht, welche Sie vorher umgesetzt haben. Durch [Vektorisierung](https://en.wikipedia.org/wiki/Array_programming) wird eine Operation nicht nur auf einem Element sondern auf jedem Element eines Arrays ausgeführt. Die Distanzberechung kann in diesem Fall deutlich effizienter gestaltet werden und ermöglichen die Teilmenge, welche Sie ausgewählt haben, zu erhöhen. Neurale Netzwerke können nur aufgrund dieser Technik gut berechnet werden, da der Aufwand sonst zu hoch wäre. Implementieren Sie die Funktion `compute_distances_vectorized` im Skript. Obwohl diese Aufgabe nicht optional ist, ist Sie nicht notwendig um fortzufahren. Sofern, die Aufgabe zu komplex ist, fahren Sie erst einmal fort oder bearbeiten andere Aufgaben als ausgleich.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task is not vital for the notebook. Run that cell only if you have implement the vectorized function\n",
    "dists_vec = classifier.compute_distances_vectorized(X_test)\n",
    "\n",
    "# check that the distance matrix agrees with the one we computed before:\n",
    "difference = np.linalg.norm(dists - dists_vec, ord='fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der erste Kernschritt war damit abgearbeitet. Es bleibt nun die geringsten Distanzen zu finden und eine rsultierdende Klasse auszuwählen. Implementieren in dem Skript hierzu die Funktion `predict.labels()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this cell: implement the function predict_labels\n",
    "y_test_pred = classifier.predict_labels(dists)\n",
    "\n",
    "# Compute and print the fraction of correctly predicted examples\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies sollte ein Ergebnis von ungefähr `27,4%` Genauigkeit erzielen. Das Aufrufen der Methode `predict.labels()` ohne spezifischen Parameter `k` hat als Standardwert `k=1` gesetzt und somit nur den direkten Nachbarn betrachtet. Wiederholen Sie die Klassifikation mit `k` gleich fünf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict_labels(dists, k=5)\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies hat eine kleine Verbesserung gebracht. Per Hand mögliche Optionen von `k` zu testen ist jedoch nicht sonderlich effizient. Im Folgenden versuchen Sie dies zu automatisieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kreuzvalidierungsverfahren\n",
    "\n",
    "Sie haben bereits den kNN-Klassifikator implementiert, jedoch in Bezug auf das Ergebnis nicht optimiert. Das Kreuzvalidierungsverfahren ([cross-validation](https://en.wikipedia.org/wiki/Cross-validation)) bietet eine Möglichkeit Optionen automatisiert zu testen und zu vergleichen. Im Rahmen von Machine Learning handelt es sich bei diesem Vorgehen im Allgemeinen um eine Hyperparameter-Optimalisierung (als Methode wird hier Kreuzvalidierungsverfahren verwendet). Es werden alle veränderlichen Werte einer Methode versucht so einzustellen, dass das beste Ergebnis erzielt wird. Implementieren tun Sie eine k-fold cross-validation:\n",
    "\n",
    ">**k-fold cross-validation**\n",
    "\n",
    ">In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged to produce a single estimation. The advantage of this method over repeated random sub-sampling (see below) is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used,[6] but in general k remains an unfixed parameter.\n",
    "\n",
    ">When k = n (the number of observations), the k-fold cross-validation is exactly the leave-one-out cross-validation.\n",
    "\n",
    ">In stratified k-fold cross-validation, the folds are selected so that the mean response value is approximately equal in all the folds. In the case of a dichotomous classification, this means that each fold contains roughly the same proportions of the two types of class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "################################################################################\n",
    "# TODO (0):                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# y_train_folds should each be lists of length num_folds, where                #\n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "#                                                                              #\n",
    "# Hint: Look up the numpy array_split function.                                #\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "################################################################################\n",
    "# TODO (5):                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of k. For each        #\n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of k in the k_to_accuracies dictionary.                               #\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie ein Scatter-Plot der die Genauigkeiten für die in der Kreuzvalidierung verwendeten `k` visualisiert. Bestimmen Sie dabei für jeden `k`-Wert sowohl das arithmetische Mittel als auch die Standardabweichung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO (0):                                                                    #\n",
    "# Create an scatter plot for each k in k_choices that plots the accuracies.    #\n",
    "# Calculate the mean and standard deviation for the accuracies of each k and   #\n",
    "# add them to the plot.                                                        #\n",
    "#                                                                              #\n",
    "# Hint: Numpy provides mean() and std() as functions, use them. You can either #\n",
    "#       use matplotlibs errorbar function to plot the mean and standard        # \n",
    "#       deviation based on k_choices.                                          #\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen Sie ein kNN-Klassifikator mit dem Hyperparameter k, der sich aus der Kreuzvalidierung ergeben hat, auf den gesamten Datensatz und geben Sie zur je einer Klasse ein Testbild mit den nächsten Nachbarn aus. Welche Genauigkeit (accuracy) erreichen Sie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO (0):                                                                    #\n",
    "# Based on your cross-validation results above, choose the best value for k,   #\n",
    "# retrain the classifier using all the training data, and test it on the test  #\n",
    "# data. Print accuracy and  k nearest neighbor images for one image of each    #\n",
    "# class.                                                                       #\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
